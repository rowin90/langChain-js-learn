{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"hi\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"hi\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"What can I do for you?\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"What can I do for you?\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "import { HumanMessage, AIMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "\n",
    "await history.addMessage(new HumanMessage(\"hi\"));\n",
    "await history.addMessage(new AIMessage(\"What can I do for you?\"));\n",
    "\n",
    "const messages = await history.getMessages();\n",
    "\n",
    "console.log(messages);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 自动维护 chat history\n",
    "\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  configuration: {\n",
    "    baseURL: 'https://api.shellgpt.top/v1',\n",
    "  },\n",
    "});\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"],\n",
    "    new MessagesPlaceholder(\"history_message\"),\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "const chain = prompt.pipe(chatModel)\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: chain,\n",
    "  getMessageHistory: (_sessionId) => history,\n",
    "  inputMessagesKey: \"input\",\n",
    "  historyMessagesKey: \"history_message\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const res1 = await chainWithHistory.invoke({\n",
    "  input: \"hi, my name is Kai\"\n",
    "},{\n",
    "  configurable: { sessionId: \"none\" }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Hello Kai! How can I assist you today?\"\u001b[39m,\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: [],\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Hello Kai! How can I assist you today?\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m10\u001b[39m, promptTokens: \u001b[33m33\u001b[39m, totalTokens: \u001b[33m43\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  },\n",
       "  tool_calls: [],\n",
       "  invalid_tool_calls: []\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const res2 = await chainWithHistory.invoke({\n",
    "  input: \"我的名字叫什么？\"\n",
    "},{\n",
    "  configurable: { sessionId: \"none\" }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"您刚刚告诉我您的名字是Kai。所以，您的名字确实是Kai。有任何其他问题我能帮到您吗？\"\u001b[39m,\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: [],\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"您刚刚告诉我您的名字是Kai。所以，您的名字确实是Kai。有任何其他问题我能帮到您吗？\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m44\u001b[39m, promptTokens: \u001b[33m60\u001b[39m, totalTokens: \u001b[33m104\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  },\n",
       "  tool_calls: [],\n",
       "  invalid_tool_calls: []\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello Kai! How can I assist you today?\"\u001b[39m,\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: [],\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello Kai! How can I assist you today?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m10\u001b[39m, promptTokens: \u001b[33m33\u001b[39m, totalTokens: \u001b[33m43\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    },\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: []\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"我的名字叫什么？\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"我的名字叫什么？\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"您刚刚告诉我您的名字是Kai。所以，您的名字确实是Kai。有任何其他问题我能帮到您吗？\"\u001b[39m,\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: [],\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"您刚刚告诉我您的名字是Kai。所以，您的名字确实是Kai。有任何其他问题我能帮到您吗？\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m44\u001b[39m, promptTokens: \u001b[33m60\u001b[39m, totalTokens: \u001b[33m104\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    },\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: []\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "await history.getMessages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, 我叫小明\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, 我叫小明\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"你好\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"你好\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { JSONChatHistory } from \"./JSONChatHistory/index.ts\"\n",
    "import { AIMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const history = new JSONChatHistory({\n",
    "    dir: \"chat_data\",\n",
    "    sessionId: \"test\"\n",
    "})\n",
    "\n",
    "\n",
    "await history.addMessages([\n",
    "  new HumanMessage(\"Hi, 我叫小明\"),\n",
    "  new AIMessage(\"你好\"),\n",
    "]);\n",
    "\n",
    "const messages = await history.getMessages();\n",
    "console.log(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 : { response: \"你叫小明。\" }\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  configuration: {\n",
    "    baseURL: 'https://api.shellgpt.top/v1',\n",
    "  },\n",
    "  temperature: 0.2,\n",
    "});\n",
    "\n",
    "const memory = new BufferMemory({\n",
    "    chatHistory: history\n",
    "});\n",
    "const chain = new ConversationChain({ llm: chatModel, memory: memory });\n",
    "const res1 = await chain.call({ input: \"我叫什么？\" });\n",
    "console.log('res1 :', res1);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
