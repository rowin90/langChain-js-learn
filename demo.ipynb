{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-a88pHzo6OaVlmyK0Ae2159A004A8492f94A5499bCc2bF7F8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"\u001b[39m,\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: [],\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m13\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m24\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  },\n",
       "  tool_calls: [],\n",
       "  invalid_tool_calls: []\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "// import OpenAI from \"openai\";\n",
    "\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { load } from \"https://deno.land/std@0.223.0/dotenv/mod.ts\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}\n",
    "\n",
    "console.log(process.env.OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://api.shellgpt.top/v1\",\n",
    "    }\n",
    "});\n",
    "\n",
    "await chatModel.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "\n",
    "// 原生 OpenAI\n",
    "// const openai = new OpenAI({\n",
    "//     baseURL: \"https://api.shellgpt.top/v1\",\n",
    "//  });\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
